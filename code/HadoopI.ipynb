{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhcMaXA5Qyqc2rlBVCrDPU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adigenova/uohpmd/blob/main/code/HadoopI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Java 8\n",
        "Hadoop es un framework de procesamiento de datos basado en java."
      ],
      "metadata": {
        "id": "khCyTGqeEj-0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntUhLC8XEcCN",
        "outputId": "31302300-7ddc-4a8d-8f81-278457d5dff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"11.0.16\" 2022-07-19\n",
            "OpenJDK Runtime Environment (build 11.0.16+8-post-Ubuntu-0ubuntu118.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.16+8-post-Ubuntu-0ubuntu118.04, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5PpGZooE786",
        "outputId": "d795003a-041a-4aab-d928-9a3e26347e29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 36.6 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u342-b07-0ubuntu1~18.04 [28.3 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u342-b07-0ubuntu1~18.04 [8,300 kB]\n",
            "Fetched 36.6 MB in 1s (48.7 MB/s)\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 159447 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u342-b07-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u342-b07-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cambiamos la version de java pro defecto (elegir 2)\n",
        "!update-alternatives --config java"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6M4pBv9FPRW",
        "outputId": "ba68a72b-68a0-4345-cecd-a6a750e8c451"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --config javac"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVqlFyjCFdDZ",
        "outputId": "927d3247-3980-41ce-c705-28b94c4f8032"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative javac (providing /usr/bin/javac).\n",
            "\n",
            "  Selection    Path                                          Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/javac   1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/javac   1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/bin/javac    1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --config jps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTzRtnRcFjkl",
        "outputId": "1326efbd-5176-4fa6-e9fd-be0edf651db3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative jps (providing /usr/bin/jps).\n",
            "\n",
            "  Selection    Path                                        Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/jps   1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/jps   1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/bin/jps    1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 2\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in manual mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3NMuLCuFqaF",
        "outputId": "7653a480-1ee0-4048-896c-5431e856296d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_342\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_342-8u342-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creación de variables de entorno relacionadas con Java\n",
        "\n",
        "JAVA_HOME es una variable de entorno del sistema operativo que apunta a la ubicación del sistema de archivos donde se instaló JDK o JRE."
      ],
      "metadata": {
        "id": "mnELy7FzF32P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#en contrando el path de java\n",
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRjK3MR7FxQG",
        "outputId": "3b408575-123d-4444-cce3-6433502add5f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64/jre/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando el module os\n",
        "import os\n",
        "#creando las variables de ambiente\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"JRE_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64/jre\"\n",
        "os.environ[\"PATH\"] += \":$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\""
      ],
      "metadata": {
        "id": "7xOy0zg7F9hv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando SSH\n",
        "\n"
      ],
      "metadata": {
        "id": "pXhaEYZ4Kwun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Necesitamos definir un medio para que el nodo maestro acceda de forma remota a todos los nodos de nuestro clúster.\n",
        "\n",
        "Hadoop utiliza frases de contraseña SSH para la comunicación entre los nodos.\n",
        "\n",
        "SSH es un protocolo de red criptográfico para operar servicios de red de forma segura en una red no segura.\n",
        "\n",
        "SSH utiliza criptografía de clave pública estándar para crear un par de claves para la verificación del usuario: una pública y otra privada"
      ],
      "metadata": {
        "id": "PRke9v59K8hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openssh-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l60zLteZKzFM",
        "outputId": "89e9b57b-9d0f-4bb4-f4ad-6fce9e8d643b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  ncurses-term openssh-sftp-server python3-certifi python3-chardet\n",
            "  python3-idna python3-pkg-resources python3-requests python3-six\n",
            "  python3-urllib3 ssh-import-id\n",
            "Suggested packages:\n",
            "  molly-guard monkeysphere rssh ssh-askpass ufw python3-setuptools\n",
            "  python3-cryptography python3-openssl python3-socks\n",
            "The following NEW packages will be installed:\n",
            "  ncurses-term openssh-server openssh-sftp-server python3-certifi\n",
            "  python3-chardet python3-idna python3-pkg-resources python3-requests\n",
            "  python3-six python3-urllib3 ssh-import-id\n",
            "0 upgraded, 11 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 1,148 kB of archives.\n",
            "After this operation, 7,609 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ncurses-term all 6.1-1ubuntu1.18.04 [248 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-sftp-server amd64 1:7.6p1-4ubuntu0.7 [45.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openssh-server amd64 1:7.6p1-4ubuntu0.7 [332 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-certifi all 2018.1.18-2 [144 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-pkg-resources all 39.0.1-2 [98.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-chardet all 3.0.4-1 [80.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-idna all 2.6-1 [32.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-six all 1.11.0-2 [11.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-urllib3 all 1.22-1ubuntu0.18.04.2 [86.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-requests all 2.18.4-2ubuntu0.1 [58.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ssh-import-id all 5.7-0ubuntu1.1 [10.9 kB]\n",
            "Fetched 1,148 kB in 1s (1,378 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package ncurses-term.\n",
            "(Reading database ... 159792 files and directories currently installed.)\n",
            "Preparing to unpack .../00-ncurses-term_6.1-1ubuntu1.18.04_all.deb ...\n",
            "Unpacking ncurses-term (6.1-1ubuntu1.18.04) ...\n",
            "Selecting previously unselected package openssh-sftp-server.\n",
            "Preparing to unpack .../01-openssh-sftp-server_1%3a7.6p1-4ubuntu0.7_amd64.deb ...\n",
            "Unpacking openssh-sftp-server (1:7.6p1-4ubuntu0.7) ...\n",
            "Selecting previously unselected package openssh-server.\n",
            "Preparing to unpack .../02-openssh-server_1%3a7.6p1-4ubuntu0.7_amd64.deb ...\n",
            "Unpacking openssh-server (1:7.6p1-4ubuntu0.7) ...\n",
            "Selecting previously unselected package python3-certifi.\n",
            "Preparing to unpack .../03-python3-certifi_2018.1.18-2_all.deb ...\n",
            "Unpacking python3-certifi (2018.1.18-2) ...\n",
            "Selecting previously unselected package python3-pkg-resources.\n",
            "Preparing to unpack .../04-python3-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python3-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python3-chardet.\n",
            "Preparing to unpack .../05-python3-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python3-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python3-idna.\n",
            "Preparing to unpack .../06-python3-idna_2.6-1_all.deb ...\n",
            "Unpacking python3-idna (2.6-1) ...\n",
            "Selecting previously unselected package python3-six.\n",
            "Preparing to unpack .../07-python3-six_1.11.0-2_all.deb ...\n",
            "Unpacking python3-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python3-urllib3.\n",
            "Preparing to unpack .../08-python3-urllib3_1.22-1ubuntu0.18.04.2_all.deb ...\n",
            "Unpacking python3-urllib3 (1.22-1ubuntu0.18.04.2) ...\n",
            "Selecting previously unselected package python3-requests.\n",
            "Preparing to unpack .../09-python3-requests_2.18.4-2ubuntu0.1_all.deb ...\n",
            "Unpacking python3-requests (2.18.4-2ubuntu0.1) ...\n",
            "Selecting previously unselected package ssh-import-id.\n",
            "Preparing to unpack .../10-ssh-import-id_5.7-0ubuntu1.1_all.deb ...\n",
            "Unpacking ssh-import-id (5.7-0ubuntu1.1) ...\n",
            "Setting up ncurses-term (6.1-1ubuntu1.18.04) ...\n",
            "Setting up python3-idna (2.6-1) ...\n",
            "Setting up python3-six (1.11.0-2) ...\n",
            "Setting up python3-certifi (2018.1.18-2) ...\n",
            "Setting up python3-pkg-resources (39.0.1-2) ...\n",
            "Setting up openssh-sftp-server (1:7.6p1-4ubuntu0.7) ...\n",
            "Setting up python3-chardet (3.0.4-1) ...\n",
            "Setting up python3-urllib3 (1.22-1ubuntu0.18.04.2) ...\n",
            "Setting up openssh-server (1:7.6p1-4ubuntu0.7) ...\n",
            "\n",
            "Creating config file /etc/ssh/sshd_config with new version\n",
            "Creating SSH2 RSA key; this may take some time ...\n",
            "2048 SHA256:skMoNTvFhvHEZQEDvn5YHotPTVA9yoXDDHxDB1b05qY root@06ebc0fd9941 (RSA)\n",
            "Creating SSH2 ECDSA key; this may take some time ...\n",
            "256 SHA256:+NB8MskQfZrmT9wSfca7adlsXSEjGqNKdYx6Bd7OsZ8 root@06ebc0fd9941 (ECDSA)\n",
            "Creating SSH2 ED25519 key; this may take some time ...\n",
            "256 SHA256:rtx4zHMD2u6BRvz6vQfy4WeDfuqs0JhgfSw1t4ByLog root@06ebc0fd9941 (ED25519)\n",
            "Created symlink /etc/systemd/system/sshd.service → /lib/systemd/system/ssh.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service → /lib/systemd/system/ssh.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up python3-requests (2.18.4-2ubuntu0.1) ...\n",
            "Setting up ssh-import-id (5.7-0ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.56) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Starting the server\n",
        "!service ssh start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7EDXyoSLAgi",
        "outputId": "52043670-86b2-4f25-b75e-7cbe93e36fc2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Starting OpenBSD Secure Shell server sshd\n",
            "   ...done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep Port /etc/ssh/sshd_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNKXUeCzLFqO",
        "outputId": "c9cd5574-a5a7-45b3-9ef6-12381e6d63fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Port 22\n",
            "#GatewayPorts no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh-keygen -t rsa -P \"\" -f ~/.ssh/id_rsa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzq6op9-LQRq",
        "outputId": "99b67b94-b6f4-4b56-f651-df8ebe459a04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating public/private rsa key pair.\n",
            "Created directory '/root/.ssh'.\n",
            "Your identification has been saved in /root/.ssh/id_rsa.\n",
            "Your public key has been saved in /root/.ssh/id_rsa.pub.\n",
            "The key fingerprint is:\n",
            "SHA256:FLsbU1TolEIOosXmFdMVFhG4czDpzxIKybQuvLBlW6A root@06ebc0fd9941\n",
            "The key's randomart image is:\n",
            "+---[RSA 2048]----+\n",
            "|   .o ++o+OO.    |\n",
            "|   o+..+B=+      |\n",
            "|  .= + .+B.      |\n",
            "|  . *  .=oo      |\n",
            "| o o . .S*       |\n",
            "|E = o . .+o      |\n",
            "| = =    ..       |\n",
            "|. o              |\n",
            "|                 |\n",
            "+----[SHA256]-----+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Copying the key to autorized keys\n",
        "!cat $HOME/.ssh/id_rsa.pub>>$HOME/.ssh/authorized_keys\n",
        "#Changing the permissions on the key\n",
        "!chmod 0600 ~/.ssh/authorized_keys"
      ],
      "metadata": {
        "id": "N0e-UAsPLUZt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conneting with the local machine\n",
        "!ssh -o StrictHostKeyChecking=no localhost uptime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhI5w6TGLXpR",
        "outputId": "2c4f2beb-f352-47d4-f9d4-7c9686124fa6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.\r\n",
            " 14:08:46 up 29 min,  0 users,  load average: 0.18, 0.12, 0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Hadoop 3.2.3"
      ],
      "metadata": {
        "id": "Xo_paSdCLc7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://archive.apache.org/dist/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB_eAifNLeuH",
        "outputId": "df6205ae-191f-4e66-d491-94567e8b9547"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-03 14:11:37--  https://archive.apache.org/dist/hadoop/common/hadoop-3.2.3/hadoop-3.2.3.tar.gz\n",
            "Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 492241961 (469M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.2.3.tar.gz’\n",
            "\n",
            "hadoop-3.2.3.tar.gz 100%[===================>] 469.44M  2.63MB/s    in 56s     \n",
            "\n",
            "2022-10-03 14:12:33 (8.36 MB/s) - ‘hadoop-3.2.3.tar.gz’ saved [492241961/492241961]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo tar -xzf hadoop-3.2.3.tar.gz\n",
        "!cp -r hadoop-3.2.3/ /usr/local/\n",
        "!ls /usr/local/hadoop-3.2.3/etc/hadoop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1BMqUQtMNxi",
        "outputId": "efa5ed6c-3c36-4583-b38e-1393179c195c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "capacity-scheduler.xml\t\t  kms-log4j.properties\n",
            "configuration.xsl\t\t  kms-site.xml\n",
            "container-executor.cfg\t\t  log4j.properties\n",
            "core-site.xml\t\t\t  mapred-env.cmd\n",
            "hadoop-env.cmd\t\t\t  mapred-env.sh\n",
            "hadoop-env.sh\t\t\t  mapred-queues.xml.template\n",
            "hadoop-metrics2.properties\t  mapred-site.xml\n",
            "hadoop-policy.xml\t\t  shellprofile.d\n",
            "hadoop-user-functions.sh.example  ssl-client.xml.example\n",
            "hdfs-site.xml\t\t\t  ssl-server.xml.example\n",
            "httpfs-env.sh\t\t\t  user_ec_policies.xml.template\n",
            "httpfs-log4j.properties\t\t  workers\n",
            "httpfs-signature.secret\t\t  yarn-env.cmd\n",
            "httpfs-site.xml\t\t\t  yarn-env.sh\n",
            "kms-acls.xml\t\t\t  yarnservice-log4j.properties\n",
            "kms-env.sh\t\t\t  yarn-site.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '/export JAVA_HOME=/a export JAVA_HOME=\\/usr\\/lib\\/jvm\\/java-8-openjdk-amd64' /usr/local/hadoop-3.2.3/etc/hadoop/hadoop-env.sh"
      ],
      "metadata": {
        "id": "JTMXlQv_Mhc7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HADOOP_HOME\"] = \"/usr/local/hadoop-3.2.3\""
      ],
      "metadata": {
        "id": "7FE7MO-ZMpds"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $HADOOP_HOME/etc/hadoop/*.xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWlny-uxMvPc",
        "outputId": "22a19d87-2a93-4555-ca50-53480749dda1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.2.3/etc/hadoop/capacity-scheduler.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/core-site.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/hadoop-policy.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/hdfs-site.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/httpfs-site.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/kms-acls.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/kms-site.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/mapred-site.xml\n",
            "/usr/local/hadoop-3.2.3/etc/hadoop/yarn-site.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat $HADOOP_HOME/etc/hadoop/core-site.xml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW_AfNd6M9X4",
        "outputId": "a6f19398-bb69-4599-c3d4-1f4132d30e73"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
            "<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n",
            "<!--\n",
            "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "  you may not use this file except in compliance with the License.\n",
            "  You may obtain a copy of the License at\n",
            "\n",
            "    http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "  Unless required by applicable law or agreed to in writing, software\n",
            "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "  See the License for the specific language governing permissions and\n",
            "  limitations under the License. See accompanying LICENSE file.\n",
            "-->\n",
            "\n",
            "<!-- Put site-specific property overrides in this file. -->\n",
            "\n",
            "<configuration>\n",
            "</configuration>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Hadoop in standalone mode\n",
        "\n",
        "Con las propiedades de configuración predeterminadas, Hadoop se ejecuta en modo independiente (modo no distribuido). Es decir, el modo independiente (también conocido como modo local) es el modo predeterminado para Hadoop.\n",
        "\n",
        "No hay demonios para ejecutar. Solo un solo proceso java\n",
        "\n",
        "Se utilizan el sistema de archivos local y el ejecutor de trabajos MapReduce local\n",
        "\n",
        "El comando para ejecutar un programa Hadoop mapreduce que está escrito en Java es:\n",
        "\n",
        "```\n",
        "$HADOOP_HOME/bin/hadoop jar <jar>\n",
        "```"
      ],
      "metadata": {
        "id": "QNb_VOY3M-4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls $HADOOP_HOME/share/hadoop/mapreduce/*.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZf6kqikNUB2",
        "outputId": "70fa7643-8c97-4f63-e55f-56677e35091e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.3-tests.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.3.jar\n",
            "/usr/local/hadoop-3.2.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplos Map/reduce"
      ],
      "metadata": {
        "id": "wzpaLSzFNj3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VePKmgiINmPz",
        "outputId": "7191eedd-0ba9-413d-f833-1c2a1b3618e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An example program must be given as the first argument.\n",
            "Valid program names are:\n",
            "  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.\n",
            "  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.\n",
            "  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.\n",
            "  dbcount: An example job that count the pageview counts from a database.\n",
            "  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.\n",
            "  grep: A map/reduce program that counts the matches of a regex in the input.\n",
            "  join: A job that effects a join over sorted, equally partitioned datasets\n",
            "  multifilewc: A job that counts words from several files.\n",
            "  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.\n",
            "  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.\n",
            "  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.\n",
            "  randomwriter: A map/reduce program that writes 10GB of random data per node.\n",
            "  secondarysort: An example defining a secondary sort to the reduce.\n",
            "  sort: A map/reduce program that sorts the data written by the random writer.\n",
            "  sudoku: A sudoku solver.\n",
            "  teragen: Generate data for the terasort\n",
            "  terasort: Run the terasort\n",
            "  teravalidate: Checking results of terasort\n",
            "  wordcount: A map/reduce program that counts the words in the input files.\n",
            "  wordmean: A map/reduce program that counts the average length of the words in the input files.\n",
            "  wordmedian: A map/reduce program that counts the median length of the words in the input files.\n",
            "  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar wordcount"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQGDQcsuNvu2",
        "outputId": "dd5ba883-3d18-46d5-dee8-842bd1a95ab0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: wordcount <in> [<in>...] <out>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  https://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/101/101.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cl1ICh5N3Vk",
        "outputId": "88de7f8d-c985-4a6f-e885-b7aceccf4dc1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-03 14:20:13--  https://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/1/0/101/101.txt\n",
            "Resolving www.mirrorservice.org (www.mirrorservice.org)... 212.219.56.184, 2001:630:341:12::184\n",
            "Connecting to www.mirrorservice.org (www.mirrorservice.org)|212.219.56.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 678064 (662K) [text/plain]\n",
            "Saving to: ‘101.txt’\n",
            "\n",
            "\r101.txt               0%[                    ]       0  --.-KB/s               \r101.txt             100%[===================>] 662.17K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-10-03 14:20:13 (10.3 MB/s) - ‘101.txt’ saved [678064/678064]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!$HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.3.jar \\\n",
        "wordcount /content/101.txt /content/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPqP2imoOBAk",
        "outputId": "5064907e-b33b-46a0-c7c0-5afba41a07ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-03 14:21:09,489 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2022-10-03 14:21:09,594 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2022-10-03 14:21:09,594 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2022-10-03 14:21:09,793 INFO input.FileInputFormat: Total input files to process : 1\n",
            "2022-10-03 14:21:09,837 INFO mapreduce.JobSubmitter: number of splits:1\n",
            "2022-10-03 14:21:10,042 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local590016641_0001\n",
            "2022-10-03 14:21:10,042 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2022-10-03 14:21:10,241 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2022-10-03 14:21:10,242 INFO mapreduce.Job: Running job: job_local590016641_0001\n",
            "2022-10-03 14:21:10,249 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2022-10-03 14:21:10,258 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-03 14:21:10,258 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-03 14:21:10,258 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
            "2022-10-03 14:21:10,316 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2022-10-03 14:21:10,317 INFO mapred.LocalJobRunner: Starting task: attempt_local590016641_0001_m_000000_0\n",
            "2022-10-03 14:21:10,348 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-03 14:21:10,348 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-03 14:21:10,389 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-03 14:21:10,396 INFO mapred.MapTask: Processing split: file:/content/101.txt:0+678064\n",
            "2022-10-03 14:21:10,499 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2022-10-03 14:21:10,500 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2022-10-03 14:21:10,500 INFO mapred.MapTask: soft limit at 83886080\n",
            "2022-10-03 14:21:10,500 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2022-10-03 14:21:10,500 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2022-10-03 14:21:10,504 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2022-10-03 14:21:10,808 INFO mapred.LocalJobRunner: \n",
            "2022-10-03 14:21:10,808 INFO mapred.MapTask: Starting flush of map output\n",
            "2022-10-03 14:21:10,808 INFO mapred.MapTask: Spilling map output\n",
            "2022-10-03 14:21:10,809 INFO mapred.MapTask: bufstart = 0; bufend = 1078906; bufvoid = 104857600\n",
            "2022-10-03 14:21:10,809 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25792448(103169792); length = 421949/6553600\n",
            "2022-10-03 14:21:11,247 INFO mapreduce.Job: Job job_local590016641_0001 running in uber mode : false\n",
            "2022-10-03 14:21:11,249 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2022-10-03 14:21:11,643 INFO mapred.MapTask: Finished spill 0\n",
            "2022-10-03 14:21:11,662 INFO mapred.Task: Task:attempt_local590016641_0001_m_000000_0 is done. And is in the process of committing\n",
            "2022-10-03 14:21:11,667 INFO mapred.LocalJobRunner: map\n",
            "2022-10-03 14:21:11,667 INFO mapred.Task: Task 'attempt_local590016641_0001_m_000000_0' done.\n",
            "2022-10-03 14:21:11,681 INFO mapred.Task: Final Counters for attempt_local590016641_0001_m_000000_0: Counters: 18\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=994673\n",
            "\t\tFILE: Number of bytes written=1178697\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=13006\n",
            "\t\tMap output records=105488\n",
            "\t\tMap output bytes=1078906\n",
            "\t\tMap output materialized bytes=318005\n",
            "\t\tInput split bytes=86\n",
            "\t\tCombine input records=105488\n",
            "\t\tCombine output records=21438\n",
            "\t\tSpilled Records=21438\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=258473984\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=678064\n",
            "2022-10-03 14:21:11,681 INFO mapred.LocalJobRunner: Finishing task: attempt_local590016641_0001_m_000000_0\n",
            "2022-10-03 14:21:11,682 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2022-10-03 14:21:11,687 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2022-10-03 14:21:11,688 INFO mapred.LocalJobRunner: Starting task: attempt_local590016641_0001_r_000000_0\n",
            "2022-10-03 14:21:11,700 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2022-10-03 14:21:11,700 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2022-10-03 14:21:11,701 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2022-10-03 14:21:11,706 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1be257e5\n",
            "2022-10-03 14:21:11,709 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2022-10-03 14:21:11,746 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2022-10-03 14:21:11,761 INFO reduce.EventFetcher: attempt_local590016641_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2022-10-03 14:21:11,818 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local590016641_0001_m_000000_0 decomp: 318001 len: 318005 to MEMORY\n",
            "2022-10-03 14:21:11,825 INFO reduce.InMemoryMapOutput: Read 318001 bytes from map-output for attempt_local590016641_0001_m_000000_0\n",
            "2022-10-03 14:21:11,827 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 318001, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->318001\n",
            "2022-10-03 14:21:11,830 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2022-10-03 14:21:11,831 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-03 14:21:11,832 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2022-10-03 14:21:11,844 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-03 14:21:11,845 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 317994 bytes\n",
            "2022-10-03 14:21:11,894 INFO reduce.MergeManagerImpl: Merged 1 segments, 318001 bytes to disk to satisfy reduce memory limit\n",
            "2022-10-03 14:21:11,896 INFO reduce.MergeManagerImpl: Merging 1 files, 318005 bytes from disk\n",
            "2022-10-03 14:21:11,899 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2022-10-03 14:21:11,899 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2022-10-03 14:21:11,901 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 317994 bytes\n",
            "2022-10-03 14:21:11,902 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-03 14:21:11,908 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2022-10-03 14:21:12,036 INFO mapred.Task: Task:attempt_local590016641_0001_r_000000_0 is done. And is in the process of committing\n",
            "2022-10-03 14:21:12,037 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
            "2022-10-03 14:21:12,038 INFO mapred.Task: Task attempt_local590016641_0001_r_000000_0 is allowed to commit now\n",
            "2022-10-03 14:21:12,041 INFO output.FileOutputCommitter: Saved output of task 'attempt_local590016641_0001_r_000000_0' to file:/content/output\n",
            "2022-10-03 14:21:12,042 INFO mapred.LocalJobRunner: reduce > reduce\n",
            "2022-10-03 14:21:12,042 INFO mapred.Task: Task 'attempt_local590016641_0001_r_000000_0' done.\n",
            "2022-10-03 14:21:12,043 INFO mapred.Task: Final Counters for attempt_local590016641_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1630715\n",
            "\t\tFILE: Number of bytes written=1732174\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=21438\n",
            "\t\tReduce shuffle bytes=318005\n",
            "\t\tReduce input records=21438\n",
            "\t\tReduce output records=21438\n",
            "\t\tSpilled Records=21438\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=17\n",
            "\t\tTotal committed heap usage (bytes)=258473984\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=235472\n",
            "2022-10-03 14:21:12,043 INFO mapred.LocalJobRunner: Finishing task: attempt_local590016641_0001_r_000000_0\n",
            "2022-10-03 14:21:12,043 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2022-10-03 14:21:12,252 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2022-10-03 14:21:12,253 INFO mapreduce.Job: Job job_local590016641_0001 completed successfully\n",
            "2022-10-03 14:21:12,267 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=2625388\n",
            "\t\tFILE: Number of bytes written=2910871\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=13006\n",
            "\t\tMap output records=105488\n",
            "\t\tMap output bytes=1078906\n",
            "\t\tMap output materialized bytes=318005\n",
            "\t\tInput split bytes=86\n",
            "\t\tCombine input records=105488\n",
            "\t\tCombine output records=21438\n",
            "\t\tReduce input groups=21438\n",
            "\t\tReduce shuffle bytes=318005\n",
            "\t\tReduce input records=21438\n",
            "\t\tReduce output records=21438\n",
            "\t\tSpilled Records=42876\n",
            "\t\tShuffled Maps =1\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=1\n",
            "\t\tGC time elapsed (ms)=17\n",
            "\t\tTotal committed heap usage (bytes)=516947968\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=678064\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=235472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DZD89ZZORB1",
        "outputId": "cb7c5f30-bf1c-42fa-9319-c54be3958582"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-r-00000  _SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -50 /content/output/part-r-00000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMG4IkXROXIs",
        "outputId": "9e3a7e23-0d2e-4c86-db51-aaf056e54e73"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"(d)\t1\n",
            "\"/H\"\t1\n",
            "\"0\"\t1\n",
            "\"02\"\t2\n",
            "\"1.\t1\n",
            "\"414\t3\n",
            "\"A\t2\n",
            "\"AT&T\t3\n",
            "\"AT&T's\t1\n",
            "\"Access\t1\n",
            "\"Acid\t3\n",
            "\"Ad-hocracy\"\t1\n",
            "\"Advanced\t1\n",
            "\"Agents\t1\n",
            "\"Al\t3\n",
            "\"All\t3\n",
            "\"American\t1\n",
            "\"An\t1\n",
            "\"And\t2\n",
            "\"Any\t1\n",
            "\"Are\t3\n",
            "\"Artificial\t1\n",
            "\"As\t1\n",
            "\"Assistant\t1\n",
            "\"Attctc\"\t2\n",
            "\"Auld\t1\n",
            "\"Autodesk,\"\t1\n",
            "\"BBS,\"\t2\n",
            "\"BIRTHPLACE\t1\n",
            "\"BRITS\t1\n",
            "\"Barry\t1\n",
            "\"Because\t1\n",
            "\"Before\t1\n",
            "\"Bell\t2\n",
            "\"Bell\"\t1\n",
            "\"BellSouth\t2\n",
            "\"Berkeley\t1\n",
            "\"Big\t1\n",
            "\"Biggest\t1\n",
            "\"Black\t3\n",
            "\"Blue\t1\n",
            "\"Bob\"\t1\n",
            "\"Bob,\t3\n",
            "\"Bob:\t1\n",
            "\"Bullet-N-Board.\"\t1\n",
            "\"Bureaucrat-ese\t1\n",
            "\"But\t4\n",
            "\"C-word.\"\t1\n",
            "\"CALIFORNIA\"\t1\n",
            "\"CC,\"\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat /content/output/part-r-00000 | sort -rn -k2,2 | head -n 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ONdp1LOckJ",
        "outputId": "079afdd5-c62c-4924-b13a-22350dea21f5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the\t5100\n",
            "of\t3356\n",
            "and\t2765\n",
            "a\t2434\n",
            "to\t2243\n",
            "in\t1693\n",
            "was\t1096\n",
            "is\t829\n",
            "for\t781\n",
            "that\t771\n",
            "The\t751\n",
            "had\t719\n",
            "with\t641\n",
            "on\t594\n",
            "as\t572\n",
            "by\t539\n",
            "it\t504\n",
            "this\t489\n",
            "not\t486\n",
            "are\t477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Hadoop in Pseudo-distributed mode\n",
        "\n",
        "En el modo Pseudodistribuido entran en juego todos los componentes distribuidos de Hadoop. Es decir, todos los demonios de Hadoop responsables del almacenamiento distribuido y el procesamiento distribuido se ejecutarán en la misma máquina.\n",
        "\n",
        "Demonios maestros:\n",
        "\n",
        "1. NameNode\n",
        "2. Resource Manager\n",
        "3. Standby NameNode\n",
        "\n",
        "Demonios esclavos:\n",
        "\n",
        "1. DataNode\n",
        "2. Node Manager"
      ],
      "metadata": {
        "id": "JCwjdIOwPIqf"
      }
    }
  ]
}