{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcF58+IIidaDCd3UINmmwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adigenova/uohpmd/blob/main/code/MPI_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install mpich"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1rCHrYWAHl9",
        "outputId": "89e3c629-99a5-44ac-ec58-11eff516619d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  hwloc-nox libmpich-dev libmpich12 libslurm37\n",
            "Suggested packages:\n",
            "  mpich-doc\n",
            "The following NEW packages will be installed:\n",
            "  hwloc-nox libmpich-dev libmpich12 libslurm37 mpich\n",
            "0 upgraded, 5 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 14.2 MB of archives.\n",
            "After this operation, 102 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libslurm37 amd64 21.08.5-2ubuntu1 [542 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 hwloc-nox amd64 2.7.0-2ubuntu1 [205 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich12 amd64 4.0-3 [5,866 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mpich amd64 4.0-3 [197 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich-dev amd64 4.0-3 [7,375 kB]\n",
            "Fetched 14.2 MB in 1s (11.6 MB/s)\n",
            "Selecting previously unselected package libslurm37.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libslurm37_21.08.5-2ubuntu1_amd64.deb ...\n",
            "Unpacking libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Selecting previously unselected package hwloc-nox.\n",
            "Preparing to unpack .../hwloc-nox_2.7.0-2ubuntu1_amd64.deb ...\n",
            "Unpacking hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Selecting previously unselected package libmpich12:amd64.\n",
            "Preparing to unpack .../libmpich12_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich12:amd64 (4.0-3) ...\n",
            "Selecting previously unselected package mpich.\n",
            "Preparing to unpack .../archives/mpich_4.0-3_amd64.deb ...\n",
            "Unpacking mpich (4.0-3) ...\n",
            "Selecting previously unselected package libmpich-dev:amd64.\n",
            "Preparing to unpack .../libmpich-dev_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich-dev:amd64 (4.0-3) ...\n",
            "Setting up libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Setting up hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Setting up libmpich12:amd64 (4.0-3) ...\n",
            "Setting up mpich (4.0-3) ...\n",
            "Setting up libmpich-dev:amd64 (4.0-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIF1GL5Y_ue7",
        "outputId": "d3973224-fe8d-4cfc-9acb-f7f1a3fdfa11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mpi_holamundo.c\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi_holamundo.c\n",
        "// An intro MPI hello world program that uses MPI_Init, MPI_Comm_size,\n",
        "// MPI_Comm_rank, MPI_Finalize, and MPI_Get_processor_name.\n",
        "//\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "  // Initialize the MPI environment. The two arguments to MPI Init are not\n",
        "  // currently used by MPI implementations, but are there in case future\n",
        "  // implementations might need the arguments.\n",
        "  MPI_Init(NULL, NULL);\n",
        "\n",
        "  // Get the number of processes\n",
        "  int world_size;\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
        "\n",
        "  // Get the rank of the process\n",
        "  int world_rank;\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
        "\n",
        "  // Get the name of the processor\n",
        "  char processor_name[MPI_MAX_PROCESSOR_NAME];\n",
        "  int name_len;\n",
        "  MPI_Get_processor_name(processor_name, &name_len);\n",
        "  if (world_rank > 5){\n",
        "  printf(\"Hola mundo desde procesador %s, ranking %d de  %d procesadores\\n\",\n",
        "         processor_name, world_rank, world_size);\n",
        "  }else{\n",
        "    printf(\"castigado ranking %d\\n\",world_rank);\n",
        "  }\n",
        "  // Finalize the MPI environment. No more MPI calls can be made after this\n",
        "  MPI_Finalize();\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mpicc -o mpi_holamundo mpi_holamundo.c"
      ],
      "metadata": {
        "id": "ZglNe_KXAapq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --oversubscribe --allow-run-as-root -np 10 ./mpi_holamundo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UE2yxYyAr8T",
        "outputId": "1557d34a-c8d8-4e7c-ded7-8033c7bc4e24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "castigado ranking 4\n",
            "Hola mundo desde procesador 6fbaed727665, ranking 8 de  10 procesadores\n",
            "Hola mundo desde procesador 6fbaed727665, ranking 6 de  10 procesadores\n",
            "castigado ranking 2\n",
            "castigado ranking 5\n",
            "castigado ranking 3\n",
            "Hola mundo desde procesador 6fbaed727665, ranking 7 de  10 procesadores\n",
            "castigado ranking 0\n",
            "castigado ranking 1\n",
            "Hola mundo desde procesador 6fbaed727665, ranking 9 de  10 procesadores\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_send_recv.c\n",
        "\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "  // Initialize the MPI environment\n",
        "  MPI_Init(NULL, NULL);\n",
        "  // Find out rank, size\n",
        "  int world_rank;\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
        "  int world_size;\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
        "\n",
        "  // Usamos almenos dos procesos para ejecutar esta tarea\n",
        "  if (world_size < 2) {\n",
        "    fprintf(stderr, \"el numero de procesos debe ser > 1 for %s\\n\", argv[0]);\n",
        "    MPI_Abort(MPI_COMM_WORLD, 1);\n",
        "  }\n",
        "\n",
        "  int number;\n",
        "  if (world_rank == 0) {\n",
        "    //Si el ranking es 0, inicializamos el numero en 10 y lo enviamos al proceso 1\n",
        "    number = 10;\n",
        "    MPI_Send(\n",
        "      /* dato         = */ &number,\n",
        "      /* cantidad        = */ 1,\n",
        "      /* typo     = */ MPI_INT,\n",
        "      /* destino  = */ 1,\n",
        "      /* tag          = */ 0,\n",
        "      /* comunicador = */ MPI_COMM_WORLD);\n",
        "  } else if (world_rank == 1) {\n",
        "    MPI_Recv(\n",
        "      /* dato         = */ &number,\n",
        "      /* cantidad        = */ 1,\n",
        "      /* tipo     = */ MPI_INT,\n",
        "      /* origen       = */ 0,\n",
        "      /* tag          = */ 0,\n",
        "      /* comunicador = */ MPI_COMM_WORLD,\n",
        "      /* stado       = */ MPI_STATUS_IGNORE);\n",
        "    printf(\"Proceso 1 recibio el numero %d desde el proceso 0\\n\", number);\n",
        "    for(int i=0; i< number; i++){\n",
        "        printf(\"Realizando iteracion %d de %d\\n\", i, number);\n",
        "    }\n",
        "  }\n",
        "  MPI_Finalize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXIT7yFRf9vE",
        "outputId": "83d1cc90-bd72-4685-da14-4b07e293000d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mpi_send_recv.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mpicc -o mpi_send_recv mpi_send_recv.c"
      ],
      "metadata": {
        "id": "qqKMHKSrhyyR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --oversubscribe --allow-run-as-root -np 4 ./mpi_send_recv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0PJLmNDh2iY",
        "outputId": "6c533121-60d5-4894-dc8c-54f98a4aec2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceso 1 recibio el numero 10 desde el proceso 0\n",
            "Realizando iteracion 0 de 10\n",
            "Realizando iteracion 1 de 10\n",
            "Realizando iteracion 2 de 10\n",
            "Realizando iteracion 3 de 10\n",
            "Realizando iteracion 4 de 10\n",
            "Realizando iteracion 5 de 10\n",
            "Realizando iteracion 6 de 10\n",
            "Realizando iteracion 7 de 10\n",
            "Realizando iteracion 8 de 10\n",
            "Realizando iteracion 9 de 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_ping_poing.c\n",
        "\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "  const int PING_PONG_LIMIT = 10;\n",
        "\n",
        "  // Initialize the MPI environment\n",
        "  MPI_Init(NULL, NULL);\n",
        "  // Find out rank, size\n",
        "  int world_rank;\n",
        "  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
        "  int world_size;\n",
        "  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
        "\n",
        "  // usamos dos procesos para esta tarea\n",
        "  if (world_size != 2) {\n",
        "    fprintf(stderr, \" utilizamos dos procesos %s\\n\", argv[0]);\n",
        "    MPI_Abort(MPI_COMM_WORLD, 1);\n",
        "  }\n",
        "\n",
        "  int ping_pong_count = 0;\n",
        "  int partner_rank = (world_rank + 1) % 2;\n",
        "  while (ping_pong_count < PING_PONG_LIMIT) {\n",
        "    if (world_rank == ping_pong_count % 2) {\n",
        "      // imcrementamos el valor antes de enviarlo\n",
        "      ping_pong_count++;\n",
        "      MPI_Send(&ping_pong_count, 1, MPI_INT, partner_rank, 0, MPI_COMM_WORLD);\n",
        "      printf(\"%d enviamos y incrementamos el contador ping_pong_count %d to %d\\n\",\n",
        "             world_rank, ping_pong_count, partner_rank);\n",
        "    } else {\n",
        "      MPI_Recv(&ping_pong_count, 1, MPI_INT, partner_rank, 0, MPI_COMM_WORLD,\n",
        "               MPI_STATUS_IGNORE);\n",
        "      printf(\"%d recibido ping_pong_count %d desde %d\\n\",\n",
        "             world_rank, ping_pong_count, partner_rank);\n",
        "    }\n",
        "  }\n",
        "  MPI_Finalize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUXTOb-Mivg9",
        "outputId": "5d2ba999-aaff-48e7-e7b8-251ff15def7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_ping_poing.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mpicc -o mpi_ping_poing mpi_ping_poing.c"
      ],
      "metadata": {
        "id": "LYMAE77Njgm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --allow-run-as-root -np 2 ./mpi_ping_poing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmKriYmejkUG",
        "outputId": "2ad5db98-2a1b-4fd6-f9ab-2f331acd78fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 enviamos y incrementamos el contador ping_pong_count 1 to 1\n",
            "1 recibido ping_pong_count 1 desde 0\n",
            "1 enviamos y incrementamos el contador ping_pong_count 2 to 0\n",
            "0 recibido ping_pong_count 2 desde 1\n",
            "0 enviamos y incrementamos el contador ping_pong_count 3 to 1\n",
            "1 recibido ping_pong_count 3 desde 0\n",
            "1 enviamos y incrementamos el contador ping_pong_count 4 to 0\n",
            "0 recibido ping_pong_count 4 desde 1\n",
            "0 enviamos y incrementamos el contador ping_pong_count 5 to 1\n",
            "1 recibido ping_pong_count 5 desde 0\n",
            "1 enviamos y incrementamos el contador ping_pong_count 6 to 0\n",
            "0 recibido ping_pong_count 6 desde 1\n",
            "0 enviamos y incrementamos el contador ping_pong_count 7 to 1\n",
            "1 recibido ping_pong_count 7 desde 0\n",
            "1 enviamos y incrementamos el contador ping_pong_count 8 to 0\n",
            "0 recibido ping_pong_count 8 desde 1\n",
            "0 enviamos y incrementamos el contador ping_pong_count 9 to 1\n",
            "1 recibido ping_pong_count 9 desde 0\n",
            "1 enviamos y incrementamos el contador ping_pong_count 10 to 0\n",
            "0 recibido ping_pong_count 10 desde 1\n"
          ]
        }
      ]
    }
  ]
}